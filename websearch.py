import streamlit as st
from duckduckgo_search import DDGS
import time
import random  # ‚úÖ –¢–µ–ø–µ—Ä—å random –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω
import requests
from bs4 import BeautifulSoup
import urllib.parse

# –°–ø–∏—Å–æ–∫ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö User-Agent —Å—Ç—Ä–æ–∫
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:126.0) Gecko/20100101 Firefox/126.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:126.0) Gecko/20100101 Firefox/126.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15.7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4 Safari/605.1.15",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0 Safari/537.36 Edg/125.0.0.0",
    "Mozilla/5.0 (Linux; Android 13; SM-S901B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.6422.147 Mobile Safari/537.36",
    "Mozilla/5.0 (iPhone; CPU iPhone OS 17_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4 Mobile/15E148 Safari/604.1"
]

# ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –¥–ª—è random
def get_random_user_agent():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π User-Agent"""
    try:
        return random.choice(USER_AGENTS)
    except IndexError:
        return USER_AGENTS[0]  # –í–µ—Ä–Ω—É—Ç—å –ø–µ—Ä–≤—ã–π User-Agent, –µ—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–ª–∞ –ø—Ä–æ–±–ª–µ–º–∞

def get_random_delay(min_delay=2.0, max_delay=5.0):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è –∞–Ω—Ç–∏-–±–∞–Ω —Å–∏—Å—Ç–µ–º—ã"""
    return random.uniform(min_delay, max_delay)

# ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω—ã URL (—É–¥–∞–ª–µ–Ω—ã –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã)
def duckduckgo_html_search(query, region='ru-ru', max_results=5):
    """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ HTML DuckDuckGo"""
    try:
        headers = {'User-Agent': get_random_user_agent()}
        params = {
            'q': query,
            'kl': region,
        }
        
        response = requests.get(
            'https://html.duckduckgo.com/html/ ',
            headers=headers,
            params=params,
            timeout=15
        )
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        results = soup.find_all('div', class_='result')
        
        formatted = []
        count = 0
        
        for result in results:
            if count >= max_results:
                break
                
            title_elem = result.find('a', class_='result__a')
            snippet_elem = result.find('a', class_='result__snippet')
            url_elem = result.find('a', class_='result__url')
            
            if not title_elem or not snippet_elem:
                continue
                
            title = title_elem.text.strip()
            snippet = snippet_elem.text.strip()[:500]
            url = url_elem['href'] if url_elem and 'href' in url_elem.attrs else '#'
            
            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏
            if url.startswith('/'):
                url = 'https://duckduckgo.com ' + url
            
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤ —Å–∞–π–¥–±–∞—Ä–µ
            with st.sidebar.expander(f"ü¶Ü {title}"):
                st.write(snippet)
                st.caption(f"URL: {url}")
            
            formatted.append(f"–†–µ–∑—É–ª—å—Ç–∞—Ç {count+1} (DuckDuckGo HTML): {title}\n{snippet}\nURL: {url}\n")
            count += 1
            
        return "\n\n".join(formatted) if formatted else "DuckDuckGo HTML: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
    
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ DuckDuckGo HTML: {str(e)}"

# ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ Brave Search (–±–µ–∑ —Ç–æ–∫–µ–Ω–∞)
def brave_search(query, region='ru', max_results=5):
    """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Brave Search (—Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ brave_search)"""
    try:
        from brave_search import search
        results = search(query, count=max_results, country=region)
        
        formatted = []
        for i, result in enumerate(results, 1):
            title = result.get('title', '')
            url = result.get('url', '')
            snippet = result.get('snippet', '')[:500] + "..." if result.get('snippet') else ''
            
            with st.sidebar.expander(f"üåê {title}"):
                st.write(snippet)
                st.caption(f"URL: {url}")
            
            formatted.append(f"–†–µ–∑—É–ª—å—Ç–∞—Ç {i} (Brave): {title}\n{snippet}\nURL: {url}\n")
        
        return "\n\n".join(formatted) if formatted else "Brave: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
    
    except ImportError:
        return "Brave Search: –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞"
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ Brave Search: {str(e)}"

# ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ Searx (–ø—É–±–ª–∏—á–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä)
def searx_search(query, max_results=5):
    """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –ø—É–±–ª–∏—á–Ω—ã–π Searx (–±–µ–∑ —Ç–æ–∫–µ–Ω–∞)"""
    try:
        headers = {'User-Agent': get_random_user_agent()}
        params = {
            'q': query,
            'format': 'json',
            'limit': max_results
        }
        
        response = requests.get(
            'https://searx.be/search ',
            headers=headers,
            params=params,
            timeout=15
        )
        response.raise_for_status()
        data = response.json()
        
        formatted = []
        for i, result in enumerate(data.get('results', [])[:max_results], 1):
            title = result.get('title', '')
            url = result.get('url', '')
            snippet = result.get('content', '')[:500] + "..." if result.get('content') else ''
            
            with st.sidebar.expander(f"üîç {title}"):
                st.write(snippet)
                st.caption(f"URL: {url}")
            
            formatted.append(f"–†–µ–∑—É–ª—å—Ç–∞—Ç {i} (Searx): {title}\n{snippet}\nURL: {url}\n")
        
        return "\n\n".join(formatted) if formatted else "Searx: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
    
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ Searx: {str(e)}"

def perform_search(query, region='ru-ru', max_results=5, max_snippet_length=800):
    """–£–ª—å—Ç—Ä–∞-–Ω–∞–¥–µ–∂–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ fallback'–∞–º–∏"""
    st.sidebar.subheader("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞")
    start_time = time.time()
    
    # –ü–æ–ø—ã—Ç–∫–∞ 1: DuckDuckGo API
    try:
        headers = {'User-Agent': get_random_user_agent()}
        
        # –ë–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º
        time.sleep(get_random_delay(3.0, 6.0))
        
        with DDGS(headers=headers, timeout=25) as ddgs:
            search_results = ddgs.text(
                query,
                region=region,
                max_results=max_results,
                backend="api"
            )
            
            if search_results:
                formatted = []
                for i, r in enumerate(search_results, 1):
                    if 'body' not in r or not r['body'] or 'title' not in r or 'href' not in r:
                        continue
                    
                    snippet = r['body'][:500] + "..." if len(r['body']) > 500 else r['body']
                    
                    with st.sidebar.expander(f"üîç {r['title']}"):
                        st.write(snippet)
                        st.caption(f"URL: {r['href']}")
                    
                    body = r['body'][:max_snippet_length] + "..." if len(r['body']) > max_snippet_length else r['body']
                    formatted.append(f"–†–µ–∑—É–ª—å—Ç–∞—Ç {i} (DDG API): {r['title']}\n{body}\nURL: {r['href']}\n")
                
                if formatted:
                    st.sidebar.success(f"–ù–∞–π–¥–µ–Ω–æ {len(formatted)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞ {time.time()-start_time:.1f} —Å–µ–∫")
                    return "\n\n".join(formatted)
    except Exception as e:
        st.sidebar.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ DuckDuckGo API: {str(e)}")
    
    # –ü–æ–ø—ã—Ç–∫–∞ 2: DuckDuckGo HTML
    try:
        time.sleep(get_random_delay(2.0, 4.0))
        html_result = duckduckgo_html_search(query, region, max_results)
        if "–û—à–∏–±–∫–∞" not in html_result and "–Ω–µ –Ω–∞–π–¥–µ–Ω—ã" not in html_result:
            st.sidebar.success(f"DuckDuckGo HTML: –Ω–∞–π–¥–µ–Ω–æ –∑–∞ {time.time()-start_time:.1f} —Å–µ–∫")
            return html_result
    except Exception as e:
        st.sidebar.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ DuckDuckGo HTML: {str(e)}")
    
    # –ü–æ–ø—ã—Ç–∫–∞ 3: Brave Search
    try:
        st.sidebar.warning("‚ö†Ô∏è –ü—Ä–æ–±—É–µ–º Brave Search...")
        time.sleep(get_random_delay(1.0, 3.0))
        brave_result = brave_search(query, region[:2], max_results)
        if "–û—à–∏–±–∫–∞" not in brave_result and "–Ω–µ –Ω–∞–π–¥–µ–Ω—ã" not in brave_result:
            st.sidebar.success(f"Brave: –Ω–∞–π–¥–µ–Ω–æ –∑–∞ {time.time()-start_time:.1f} —Å–µ–∫")
            return brave_result
    except Exception as e:
        st.sidebar.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Brave Search: {str(e)}")
    
    # –ü–æ–ø—ã—Ç–∫–∞ 4: Searx
    try:
        st.sidebar.warning("‚ö†Ô∏è –ü—Ä–æ–±—É–µ–º Searx...")
        time.sleep(get_random_delay(1.0, 3.0))
        searx_result = searx_search(query, max_results)
        if "–û—à–∏–±–∫–∞" not in searx_result and "–Ω–µ –Ω–∞–π–¥–µ–Ω—ã" not in searx_result:
            st.sidebar.success(f"Searx: –Ω–∞–π–¥–µ–Ω–æ –∑–∞ {time.time()-start_time:.1f} —Å–µ–∫")
            return searx_result
    except Exception as e:
        st.sidebar.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Searx: {str(e)}")
    
    # –ü–æ–ø—ã—Ç–∫–∞ 5: –†–µ–∑–µ—Ä–≤–Ω—ã–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Mojeek
    try:
        st.sidebar.warning("‚ö†Ô∏è –ü—Ä–æ–±—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤–∏–∫...")
        time.sleep(get_random_delay(1.0, 3.0))
        headers = {'User-Agent': get_random_user_agent()}
        params = {
            "q": query,
            "s": max_results
        }
        
        response = requests.get(
            "https://www.mojeek.com/search ",
            headers=headers,
            params=params,
            timeout=15
        )
        response.raise_for_status()
        data = response.text
        soup = BeautifulSoup(data, 'html.parser')
        results = soup.find_all('li', class_='res')
        
        formatted = []
        count = 0
        
        for result in results:
            if count >= max_results:
                break
                
            title_elem = result.find('h2', class_='title')
            snippet_elem = result.find('div', class_='s')
            url_elem = title_elem.find('a') if title_elem else None
            
            if not title_elem or not snippet_elem or not url_elem:
                continue
                
            title = title_elem.text.strip()
            snippet = snippet_elem.text.strip()[:500]
            url = url_elem['href'] if 'href' in url_elem.attrs else '#'
            
            with st.sidebar.expander(f"üåê {title}"):
                st.write(snippet)
                st.caption(f"URL: {url}")
            
            formatted.append(f"–†–µ–∑—É–ª—å—Ç–∞—Ç {count+1} (Mojeek): {title}\n{snippet}\nURL: {url}\n")
            count += 1
        
        if formatted:
            st.sidebar.success(f"Mojeek: –Ω–∞–π–¥–µ–Ω–æ –∑–∞ {time.time()-start_time:.1f} —Å–µ–∫")
            return "\n\n".join(formatted)
    except Exception as e:
        st.sidebar.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Mojeek: {str(e)}")
    
    # –ï—Å–ª–∏ –≤—Å–µ –º–µ—Ç–æ–¥—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏
    st.sidebar.error("‚ùå –í—Å–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
    return "–ü–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
