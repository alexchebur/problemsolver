
import streamlit as st
import google.generativeai as genai
import time
import traceback
from docx import Document
from io import BytesIO

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ API
api_key = "AIzaSyCGC2JB3BgfBMycbt4us1eq6D5exNOvKT8"
#st.secrets.get('GEMINI_API_KEY') or st.text_input("–í–≤–µ–¥–∏—Ç–µ API-–∫–ª—é—á:", type="password")
if not api_key:
    st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ API-–∫–ª—é—á")
    st.stop()

genai.configure(
    api_key=api_key,
    transport='rest',
    client_options={
        'api_endpoint': 'generativelanguage.googleapis.com/'
    }
)

model = genai.GenerativeModel('gemini-2.0-flash')

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
if 'current_doc_text' not in st.session_state:
    st.session_state.current_doc_text = ""
if 'processing' not in st.session_state:
    st.session_state.processing = False

REASONING_STEPS = [
    "–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–Ω–µ –º–µ–Ω–µ–µ 5000 –∑–Ω–∞–∫–æ–≤, –ù–ï –£–ü–û–ú–ò–ù–ê–ô –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–Ω–∞–∫–æ–≤)",
    "–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ –∏ –º–µ—Ç–æ–¥–æ–≤ —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º",
    "–§–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞ –∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π"
]

def parse_docx(uploaded_file):
    try:
        if uploaded_file is None:
            return False

        doc = Document(BytesIO(uploaded_file.getvalue()))
        full_text = "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
        st.session_state.current_doc_text = full_text[:400000]
        st.success(f"üìÇ –î–æ–∫—É–º–µ–Ω—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {len(st.session_state.current_doc_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        return True
    except Exception as e:
        st.error(f"üö® –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}")
        st.session_state.current_doc_text = ""
        return False

def process_step(step_num, step_name, context, temperature):
    try:
        step_text = st.empty()
        step_text.markdown(f"**üîπ –®–∞–≥ {step_num+1}/{len(REASONING_STEPS)}: {step_name}**")
        
        response = model.generate_content(
            f"–í—ã–ø–æ–ª–Ω–∏—Ç–µ —à–∞–≥ {step_num+1}: {step_name}\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}",
            generation_config={
                "temperature": temperature,
                "max_output_tokens": 9000
            },
            request_options={'timeout': 60}
        )

        result = response.text
        step_text.markdown(f"**‚úÖ –®–∞–≥ {step_num+1} –∑–∞–≤–µ—Ä—à–µ–Ω**")
        st.markdown(f"---\n{result}\n---")
        return result

    except Exception as e:
        error_msg = f"üö® –û—à–∏–±–∫–∞ –Ω–∞ —à–∞–≥–µ {step_num+1}: {str(e)}"
        st.error(error_msg)
        return error_msg

def generate_response():
    st.session_state.processing = True
    status_area = st.empty()
    progress_bar = st.progress(0)
    results_container = st.container()
    
    try:
        query = st.session_state.input_query.strip()
        if not query:
            status_area.warning("‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å")
            return

        if not st.session_state.current_doc_text:
            status_area.warning("‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç")
            return

        context = (
            f"{st.session_state.sys_prompt}\n"
            f"–î–æ–∫—É–º–µ–Ω—Ç:\n{st.session_state.current_doc_text}\n"
            f"–ó–∞–ø—Ä–æ—Å: {query}"
        )

        responses = []
        with results_container:
            for step_num, step_name in enumerate(REASONING_STEPS):
                progress = int((step_num+1)/len(REASONING_STEPS)*100)
                progress_bar.progress(progress)
                
                result = process_step(
                    step_num, 
                    step_name, 
                    context, 
                    st.session_state.temperature
                )
                responses.append(result)
                time.sleep(1)

        try:
            status_area.info("üìù –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞...")
            report_content = "–û–±–æ–±—â–∏—Ç–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ MARKDOWN:\n" + "\n".join(responses)
            final_response = model.generate_content(
                report_content,
                request_options={'timeout': 40}
            )
            
            st.divider()
            st.subheader("–ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç")
            st.markdown(final_response.text)
            
        except Exception as e:
            st.error(f"üö® –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {str(e)}")

    except Exception as e:
        st.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        traceback.print_exception(e)
    finally:
        st.session_state.processing = False
        progress_bar.empty()

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit
st.title("Gemini Troubleshooter")
st.subheader("–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤")

# –û—Å–Ω–æ–≤–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
st.text_area(
    "–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç:",
    value="–í—ã - troubleshooter, —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ —Ä–µ—à–µ–Ω–∏—é –ø—Ä–æ–±–ª–µ–º –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –æ—Ç—Ä–∞—Å–ª—è—Ö –∑–Ω–∞–Ω–∏–π –∏ –∂–∏–∑–Ω–µ–¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. "
    "–ü–æ–º–æ–≥–∞–π—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—É –∏ –ø—Ä–µ–¥–ª–∞–≥–∞—Ç—å –ø—É—Ç–∏ –µ–µ —Ä–µ—à–µ–Ω–∏—è. –†—É–∫–æ–≤–æ–¥—Å—Ç–≤—É–π—Ç–µ—Å—å –º–µ—Ç–æ–¥–∞–º–∏ First Principles Thinking, "
    "Inversion (thinking backwards), Opportunity Cost, Second-Order Thinking, Margin of Diminishing Returns, Occam‚Äôs Razor, "
    "Hanlon‚Äôs Razor, Confirmation Bias, Availability Heuristic, Parkinson‚Äôs Law, Loss Aversion, Switching Costs, "
    "Circle of Competence, Regret Minimization, Leverage Points, Pareto Principle (80/20 Rule), Lindy Effect, Game Theory, "
    "System 1 vs System 2 Thinking, Antifragility, –¢–µ–æ—Ä–∏–∏ —Ä–µ—à–µ–Ω–∏—è –∏–∑–æ–±—Ä–µ—Ç–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–¥–∞—á. –û—Ç–≤–µ—á–∞–π—Ç–µ –ø–æ-—Ä—É—Å—Å–∫–∏",
    height=200,
    key="sys_prompt"
)

col1, col2 = st.columns([3, 1])
with col1:
    st.text_input(
        "–í–∞—à –∑–∞–ø—Ä–æ—Å:",
        placeholder="–û–ø–∏—à–∏—Ç–µ –≤–∞—à—É –ø—Ä–æ–±–ª–µ–º—É...",
        key="input_query"
    )
with col2:
    st.slider(
        "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞:",
        0.0, 1.0, 0.3, 0.1,
        key="temperature"
    )

st.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ DOCX —Ñ–∞–π–ª —Å –ª—é–±—ã–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º (–Ω–µ –±–æ–ª–µ–µ 300 —Ç—ã—Å. —Å–∏–º–≤–æ–ª–æ–≤):",
    type=["docx"],
    key="uploaded_file",
    on_change=lambda: parse_docx(st.session_state.uploaded_file)
)

if st.session_state.uploaded_file and not st.session_state.current_doc_text:
    parse_docx(st.session_state.uploaded_file)

if st.button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å", disabled=st.session_state.processing):
    generate_response()

if st.session_state.processing:
    st.info("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞...")
